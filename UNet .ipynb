{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'mlenv (Python 3.9.18)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Ensure TensorFlow uses GPU if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU is available and memory growth is set\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Graphviz\\bin'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator to load data in batches\n",
    "def load_data_in_batches(patient_list, batch_size):\n",
    "    while True:\n",
    "        np.random.shuffle(patient_list)\n",
    "        \n",
    "        for i in range(0, len(patient_list), batch_size):\n",
    "            batch_patients = patient_list[i:i+batch_size]\n",
    "            images, masks = [], []\n",
    "            \n",
    "            for patient in batch_patients:\n",
    "                patient_path = os.path.join('Data/BraTS2021', patient)\n",
    "                \n",
    "                flair_path = os.path.join(patient_path, f'{patient}_flair.nii')\n",
    "                t1ce_path = os.path.join(patient_path, f'{patient}_t1ce.nii')\n",
    "                t2_path = os.path.join(patient_path, f'{patient}_t2.nii')\n",
    "                seg_path = os.path.join(patient_path, f'{patient}_seg.nii')\n",
    "                \n",
    "                # Load the images using nibabel\n",
    "                flair = nib.load(flair_path).get_fdata()\n",
    "                t1ce = nib.load(t1ce_path).get_fdata()\n",
    "                t2 = nib.load(t2_path).get_fdata()\n",
    "                seg = nib.load(seg_path).get_fdata()\n",
    "                \n",
    "                # Stack the modalities (flair, t1ce, t2) along the channel axis\n",
    "                stacked_image = np.stack([flair, t1ce, t2], axis=-1)\n",
    "                \n",
    "                images.append(stacked_image)\n",
    "                masks.append(seg)\n",
    "            \n",
    "            # Convert to numpy arrays and normalize\n",
    "            images = np.array(images)\n",
    "            masks = np.expand_dims(np.array(masks), axis=-1)\n",
    "\n",
    "            # Normalize\n",
    "            images = images / np.max(images)  # Normalize images\n",
    "            masks = masks / np.max(masks)  # Normalize masks\n",
    "            \n",
    "            yield images, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of patients\n",
    "patients = os.listdir('Data/BraTS2021')\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_patients, val_patients = train_test_split(patients, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 1  # Adjust batch size depending on memory\n",
    "\n",
    "# Set up training and validation generators\n",
    "train_generator = load_data_in_batches(train_patients, batch_size)\n",
    "val_generator = load_data_in_batches(val_patients, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a batch from the training set\n",
    "train_generator = load_data_in_batches(train_patients, batch_size)\n",
    "\n",
    "# Get one batch of images and masks\n",
    "images, masks = next(train_generator)\n",
    "\n",
    "# Visualize some of the images and masks\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "for i in range(1):\n",
    "    axes[0, i].imshow(images[i, :, :, images.shape[3]//2, 0], cmap='gray')\n",
    "    axes[0, i].set_title(f\"Image {i+1}\")\n",
    "    axes[1, i].imshow(masks[i, :, :, masks.shape[3]//2], cmap='gray')\n",
    "    axes[1, i].set_title(f\"Mask {i+1}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define U-Net model architecture\n",
    "def unet_model(input_shape=(240, 240, 155, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    p1 = layers.MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(p1)\n",
    "    p2 = layers.MaxPooling3D((2, 2, 2))(c2)\n",
    "    \n",
    "    # Decoder\n",
    "    u1 = layers.UpSampling3D((2, 2, 2))(p2)\n",
    "    c3 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(u1)\n",
    "    \n",
    "    u2 = layers.UpSampling3D((2, 2, 2))(c3)\n",
    "    outputs = layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(u2)\n",
    "    \n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Instantiate model\n",
    "model = unet_model()\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function for precision, recall, and f1-score\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = (y_pred.flatten() > 0.5).astype(np.uint8)\n",
    "\n",
    "    acc = accuracy_score(y_true_flat, y_pred_flat)\n",
    "    precision = precision_score(y_true_flat, y_pred_flat)\n",
    "    recall = recall_score(y_true_flat, y_pred_flat)\n",
    "    f1 = f1_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "    return acc, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(train_patients) // batch_size\n",
    "validation_steps = len(val_patients) // batch_size\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    for step in range(steps_per_epoch):\n",
    "        images, masks = next(train_generator)\n",
    "        batch_loss = model.train_on_batch(images, masks)\n",
    "\n",
    "        # Track metrics for every batch\n",
    "        print(f\"Epoch: {epoch+1}, Batch: {step+1}/{steps_per_epoch}, Loss: {batch_loss[0]}, Accuracy: {batch_loss[1]}\")\n",
    "        \n",
    "        train_loss += batch_loss[0]\n",
    "\n",
    "    # Validation at the end of each epoch\n",
    "    val_images, val_masks = next(val_generator)\n",
    "    val_loss, val_acc = model.evaluate(val_images, val_masks)\n",
    "    \n",
    "    # Metrics calculation\n",
    "    acc, precision, recall, f1 = calculate_metrics(val_masks, model.predict(val_images))\n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_acc}, Precision: {precision}, Recall: {recall}, F1-score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('unet_model.h5')\n",
    "print(\"Model saved.\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = models.load_model('unet_model.h5')\n",
    "print(\"Model loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the loaded model\n",
    "val_images, val_masks = next(val_generator)\n",
    "predictions = loaded_model.predict(val_images)\n",
    "\n",
    "# Plot the prediction vs ground truth for a few samples\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "for i in range(1):\n",
    "    # Ground truth mask\n",
    "    axes[0, i].imshow(val_masks[i, :, :, val_masks.shape[3]//2], cmap='gray')\n",
    "    axes[0, i].set_title(f\"Ground Truth {i+1}\")\n",
    "    \n",
    "    # Predicted mask\n",
    "    axes[1, i].imshow(predictions[i, :, :, predictions.shape[3]//2], cmap='gray')\n",
    "    axes[1, i].set_title(f\"Predicted Mask {i+1}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics for the validation data\n",
    "acc, precision, recall, f1 = calculate_metrics(val_masks, predictions)\n",
    "print(f'Final Metrics -> Accuracy: {acc}, Precision: {precision}, Recall: {recall}, F1-score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model.load_state_dict(torch.load('tumor_segmentation_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Validation\n",
    "val_generator = load_data_in_batches(val_patients, batch_size)\n",
    "\n",
    "# Iterate through the validation set and visualize results\n",
    "for batch_idx, (images, masks) in enumerate(val_generator):\n",
    "    images, masks = convert_to_tensor((images, masks), device)\n",
    "    \n",
    "    # Forward pass (no gradient calculation for validation)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    \n",
    "    pred_masks = outputs.detach().cpu().numpy().round()\n",
    "    true_masks = masks.cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_acc = accuracy_score(true_masks.flatten(), pred_masks.flatten())\n",
    "    val_prec = precision_score(true_masks.flatten(), pred_masks.flatten(), zero_division=0)\n",
    "    val_recall = recall_score(true_masks.flatten(), pred_masks.flatten(), zero_division=0)\n",
    "    val_f1 = f1_score(true_masks.flatten(), pred_masks.flatten(), zero_division=0)\n",
    "\n",
    "    # Print metrics for each batch\n",
    "    print(f\"Validation Batch [{batch_idx+1}], \"\n",
    "          f\"Acc: {val_acc:.4f}, Prec: {val_prec:.4f}, \"\n",
    "          f\"Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Visualize ground truth vs prediction for the current batch\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Original Image\n",
    "    axes[0, 0].imshow(images.cpu().numpy()[0, 0, :, :, images.shape[3]//2], cmap='gray')\n",
    "    axes[0, 0].set_title(\"Original Image\")\n",
    "\n",
    "    # Ground Truth Mask\n",
    "    axes[0, 1].imshow(true_masks[0, :, :, true_masks.shape[3]//2], cmap='gray')\n",
    "    axes[0, 1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    # Predicted Mask\n",
    "    axes[1, 1].imshow(pred_masks[0, :, :, pred_masks.shape[3]//2], cmap='gray')\n",
    "    axes[1, 1].set_title(\"Predicted Mask\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    if batch_idx == 0:  # Stop after visualizing the first batch\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
